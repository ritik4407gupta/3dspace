# 3dspace

‚ú® Real-Time Hand-Gesture Controlled 3D Particle System

üîó Live Demo:
https://particle-system-6k0m-dualite.netlify.app

This project is a real-time interactive 3D particle system built using Three.js, focused on creating a natural and immersive way for users to interact with digital visuals using hand gestures, manual controls, and responsive design principles.

The experience combines camera-based hand tracking with traditional interaction methods, allowing users to control animations both physically (via hand gestures) and manually, ensuring accessibility and flexibility across different devices and environments.

A live camera preview appears in the top-right corner of the screen, showing the user‚Äôs real-time movement. This small overlay helps users clearly understand how their physical actions influence the animation, strengthening the connection between the real and virtual worlds.

üñêÔ∏è Interaction & Control

The system is designed to support:

Hand gesture control using the device camera

Manual interaction controls as a fallback and enhancement

Responsive behavior, adapting smoothly across screen sizes

Wherever the user moves their hand, the particle system is expected to follow the same direction and motion in real time. The animation should feel fluid, intuitive, and directly driven by the user‚Äînot automated or pre-scripted.

Currently, hand detection accuracy is an active focus, as reliable tracking is critical to delivering a true gesture-controlled experience.

üåå Visual Experience

The particle system showcases a range of dynamic visual behaviors visible throughout the website, including:

Smooth particle motion and flow

Real-time color transitions

Expanding and contracting particle fields

Shape-based particle formations such as Saturn-like rings, abstract orbits, and energetic bursts

A solar-system-inspired environment, where particles orbit and react as if guided by gravity controlled by the user

Every animation is rendered in real time, creating a visually rich and engaging experience that feels alive and reactive.


üéØ Project Goals

Build an interactive hand-gesture controlled particle system on the web

Combine classic motion principles with modern 3D web technologies

Provide both gesture-based and manual control

Ensure responsive performance across devices

Create a foundation for interactive art, creative coding, experimental UI, and immersive web experiences

üöß Current Focus & Improvements

Fixing and stabilizing hand detection and tracking

Improving responsiveness between hand movement and animation

Enhancing realism and visual depth

Adding more interactive animation modes
The goal of this project is to make interaction feel intuitive, immersive, and responsive‚Äîas if the user is physically shaping the digital world in front of them. Inspired by classic ideas of motion and balance, but built with modern web technologies, this project blends tradition with forward-thinking visual experimentation.

This system can be extended for interactive art installations, creative coding experiments, AR/VR prototypes, or educational visualizations, serving as a foundation for gesture-driven experiences on the web.
